#!/usr/bin/env python3
"""
Correct Database-Integrated Nightly Enablement Processor
Tracks ONLY circuits changing from "Ready for Enablement" to "Enabled" by Site ID
"""

import os
import sys
import logging
import psycopg2
from psycopg2.extras import execute_values
from datetime import datetime, timezone, timedelta
import pandas as pd
import glob

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import Config

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/nightly-enablement-db.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def get_db_connection():
    """Get database connection using config"""
    import re
    match = re.match(r'postgresql://(.+):(.+)@(.+):(\d+)/(.+)', Config.SQLALCHEMY_DATABASE_URI)
    if not match:
        raise ValueError("Invalid database URI")
    
    user, password, host, port, database = match.groups()
    
    return psycopg2.connect(
        host=host,
        port=int(port),
        database=database,
        user=user,
        password=password
    )

def process_csv_file(file_path):
    """Process a single CSV file and return circuit data by Site ID"""
    try:
        df = pd.read_csv(file_path, low_memory=False)
        logger.info(f"Processing {file_path}: {len(df)} rows")
        
        # Extract date from filename
        filename = os.path.basename(file_path)
        import re
        date_match = re.search(r'(\d{4}-\d{2}-\d{2})', filename)
        file_date = date_match.group(1) if date_match else None
        
        if not file_date:
            logger.warning(f"Skipping file with invalid date: {filename}")
            return None, file_date
        
        # Create circuit records BY SITE ID
        circuits_by_site = {}
        
        for _, row in df.iterrows():
            site_id = str(row.get('Site ID', '')).strip()
            if not site_id:
                continue
                
            # Store the row data for this site ID
            circuits_by_site[site_id] = {
                'site_id': site_id,
                'site_name': str(row.get('Site Name', '')).strip(),
                'circuit_purpose': str(row.get('Circuit Purpose', '')).strip(),
                'status': str(row.get('status', '')).strip(),
                'provider_name': str(row.get('provider_name', '')).strip(),
                'service_speed': str(row.get('details_service_speed', '')).strip(),
                'monthly_cost': row.get('billing_monthly_cost', 0),
                'assigned_to': str(row.get('SCTASK Assignee', '')).strip(),
                'sctask': str(row.get('SCTASK Number', '')).strip(),
                'record_number': str(row.get('record_number', '')).strip(),
                'file_date': file_date
            }
        
        return circuits_by_site, file_date
        
    except Exception as e:
        logger.error(f"Error processing {file_path}: {e}")
        return None, None

def detect_enablements(conn):
    """Detect circuits that transitioned from Ready for Enablement to Enabled by Site ID"""
    cursor = conn.cursor()
    
    try:
        # Get all CSV files in chronological order
        csv_dir = "/var/www/html/circuitinfo"
        csv_files = glob.glob(f"{csv_dir}/tracking_data_*.csv")
        
        # Filter out dedup files and other non-standard files
        csv_files = [f for f in csv_files if '_dedup' not in f and 'sample' not in f.lower()]
        csv_files.sort()
        
        # Only process files from last 90 days
        cutoff_date = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
        csv_files = [f for f in csv_files if f.split('tracking_data_')[1][:10] >= cutoff_date]
        
        logger.info(f"Found {len(csv_files)} CSV files to process")
        
        previous_circuits = {}
        total_enablements = 0
        
        # Clear existing data for reprocessing
        cursor.execute("DELETE FROM daily_enablements WHERE date >= CURRENT_DATE - INTERVAL '90 days'")
        cursor.execute("DELETE FROM enablement_summary WHERE summary_date >= CURRENT_DATE - INTERVAL '90 days'")
        cursor.execute("DELETE FROM ready_queue_daily WHERE summary_date >= CURRENT_DATE - INTERVAL '90 days'")
        
        for csv_file in csv_files:
            circuits_by_site, file_date = process_csv_file(csv_file)
            
            if circuits_by_site is None:
                continue
            
            daily_enablements = 0
            daily_ready_count = 0
            
            # Count ready for enablement circuits
            for site_id, circuit in circuits_by_site.items():
                status_lower = circuit['status'].lower()
                if 'ready for enablement' in status_lower:
                    daily_ready_count += 1
            
            # Check each site for Ready -> Enabled transition
            for site_id, circuit in circuits_by_site.items():
                current_status = circuit['status'].lower()
                
                # Check if this site transitioned from Ready to Enabled
                if site_id in previous_circuits:
                    prev_status = previous_circuits[site_id]['status'].lower()
                    
                    # Specific check: was "ready for enablement" and now "enabled" (but not "ready for enablement")
                    if ('ready for enablement' in prev_status and 
                        'enabled' in current_status and 
                        'ready for enablement' not in current_status):
                        
                        # This is a true Ready->Enabled transition!
                        daily_enablements += 1
                        
                        # Get assigned_to from circuits table using record_number if available, fallback to site_name
                        record_number = circuit.get('record_number', '')
                        if record_number:
                            cursor.execute("""
                                SELECT assigned_to FROM circuits 
                                WHERE record_number = %s 
                                LIMIT 1
                            """, (record_number,))
                        else:
                            cursor.execute("""
                                SELECT assigned_to FROM circuits 
                                WHERE site_name = %s 
                                ORDER BY CASE WHEN record_number IS NOT NULL THEN 0 ELSE 1 END
                                LIMIT 1
                            """, (circuit['site_name'],))
                        result = cursor.fetchone()
                        assigned_to = result[0] if result and result[0] else ''
                        
                        # Insert into daily_enablements with assignment info
                        cursor.execute("""
                            INSERT INTO daily_enablements (
                                date, site_name, circuit_purpose, provider_name,
                                service_speed, monthly_cost, previous_status, current_status,
                                assigned_to, sctask, created_at
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW())
                        """, (
                            file_date,
                            circuit['site_name'],
                            circuit['circuit_purpose'],
                            circuit['provider_name'],
                            circuit['service_speed'],
                            circuit['monthly_cost'],
                            previous_circuits[site_id]['status'],
                            circuit['status'],
                            assigned_to,  # Use from database lookup
                            circuit['sctask']
                        ))
                        
                        total_enablements += 1
                        
                        if daily_enablements <= 3:  # Log first few examples
                            logger.info(f"  Example: {site_id} ({circuit['site_name']}) changed from '{prev_status}' to '{current_status}'")
            
            # Store daily summary
            cursor.execute("""
                INSERT INTO enablement_summary (
                    summary_date, daily_count, created_at
                ) VALUES (%s, %s, %s)
                ON CONFLICT (summary_date) DO UPDATE SET
                    daily_count = EXCLUDED.daily_count,
                    created_at = EXCLUDED.created_at
            """, (file_date, daily_enablements, datetime.now(timezone.utc)))
            
            # Store ready queue count
            cursor.execute("""
                INSERT INTO ready_queue_daily (
                    summary_date, ready_count, created_at
                ) VALUES (%s, %s, %s)
                ON CONFLICT (summary_date) DO UPDATE SET
                    ready_count = EXCLUDED.ready_count,
                    created_at = EXCLUDED.created_at
            """, (file_date, daily_ready_count, datetime.now(timezone.utc)))
            
            logger.info(f"Date {file_date}: {daily_enablements} Ready->Enabled transitions, {daily_ready_count} ready")
            
            # Update previous_circuits for next iteration
            previous_circuits = circuits_by_site
        
        # Calculate trends
        calculate_trends(cursor)
        
        conn.commit()
        logger.info(f"Total Ready->Enabled transitions processed: {total_enablements}")
        return True
        
    except Exception as e:
        logger.error(f"Error detecting enablements: {e}")
        import traceback
        logger.error(traceback.format_exc())
        conn.rollback()
        return False
    finally:
        cursor.close()

def calculate_trends(cursor):
    """Calculate weekly and monthly trends with proper conflict handling"""
    try:
        # Clear existing trends for the last 90 days to avoid conflicts
        cursor.execute("DELETE FROM enablement_trends WHERE period_start >= CURRENT_DATE - INTERVAL '90 days'")
        
        # Calculate weekly trends
        cursor.execute("""
            INSERT INTO enablement_trends (
                period_type, period_start, period_end, enablement_count, created_at
            )
            SELECT 
                'weekly',
                DATE_TRUNC('week', summary_date::date),
                DATE_TRUNC('week', summary_date::date) + INTERVAL '6 days',
                SUM(daily_count),
                NOW()
            FROM enablement_summary 
            WHERE summary_date >= CURRENT_DATE - INTERVAL '90 days'
            GROUP BY DATE_TRUNC('week', summary_date::date)
        """)
        
        # Calculate monthly trends
        cursor.execute("""
            INSERT INTO enablement_trends (
                period_type, period_start, period_end, enablement_count, created_at
            )
            SELECT 
                'monthly',
                DATE_TRUNC('month', summary_date::date),
                DATE_TRUNC('month', summary_date::date) + INTERVAL '1 month' - INTERVAL '1 day',
                SUM(daily_count),
                NOW()
            FROM enablement_summary 
            WHERE summary_date >= CURRENT_DATE - INTERVAL '90 days'
            GROUP BY DATE_TRUNC('month', summary_date::date)
        """)
        
        logger.info("Trend calculations completed")
        
    except Exception as e:
        logger.error(f"Error calculating trends: {e}")

def create_enablement_tables(conn):
    """Create enablement tracking tables if they don't exist"""
    cursor = conn.cursor()
    
    try:
        # Ready queue daily tracking
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS ready_queue_daily (
                id SERIAL PRIMARY KEY,
                summary_date DATE UNIQUE,
                ready_count INTEGER,
                created_at TIMESTAMP DEFAULT NOW()
            )
        """)
        
        # Enablement trends
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS enablement_trends (
                id SERIAL PRIMARY KEY,
                period_type VARCHAR(20),
                period_start DATE,
                period_end DATE,
                enablement_count INTEGER,
                created_at TIMESTAMP DEFAULT NOW(),
                UNIQUE(period_type, period_start)
            )
        """)
        
        # Create indexes
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_ready_queue_date ON ready_queue_daily(summary_date);
            CREATE INDEX IF NOT EXISTS idx_trends_period ON enablement_trends(period_type, period_start);
        """)
        
        conn.commit()
        logger.info("Enablement tables created/verified")
        
    except Exception as e:
        logger.error(f"Error creating enablement tables: {e}")
        conn.rollback()
        raise
    finally:
        cursor.close()

def main():
    """Main processing function"""
    logger.info("Starting CORRECT nightly enablement processing (Ready->Enabled by Site ID)")
    
    try:
        # Get database connection
        conn = get_db_connection()
        
        # Create tables if needed
        create_enablement_tables(conn)
        
        # Process enablement data
        success = detect_enablements(conn)
        
        if success:
            logger.info("Correct enablement processing completed successfully")
        else:
            logger.error("Correct enablement processing failed")
            return False
            
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"Error in main process: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)